{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.024] global loadsave.cpp:244 findDecoder imread_('images/hsvcalibimagemarchingants2.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb Cell 1\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m frame_org \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mimages/hsvcalibimagemarchingants2.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bot_stream_width, bot_stream_height_org \u001b[39m=\u001b[39m frame_org\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], frame_org\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m width, height \u001b[39m=\u001b[39m bot_stream_width, bot_stream_height_org\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mice/Desktop/robawt2023/pi/keeponcom.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m height_lt \u001b[39m=\u001b[39m bot_stream_height_org\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "frame_org = cv2.imread('images/hsvcalibimagemarchingants2.jpg')\n",
    "bot_stream_width, bot_stream_height_org = frame_org.shape[1], frame_org.shape[0]\n",
    "width, height = bot_stream_width, bot_stream_height_org\n",
    "height_lt = bot_stream_height_org\n",
    "cv2.imshow('image', frame_org)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #~ Trapezium-ish mask \n",
    "# height_lt = 480; width_lt = 640; centre_x_lt = 640 // 2\n",
    "# crop_bot_h = 60\n",
    "# higher_crop_triangle_h = 72\n",
    "# higher_crop_triangle_w = 75\n",
    "# higher_crop_triangle_gap_w = 35\n",
    "\n",
    "# mask_trapeziums = np.zeros([height_lt, width_lt], dtype=\"uint8\")\n",
    "# left_triangle_pts = np.array([[0, height_lt - crop_bot_h], [0, height_lt - higher_crop_triangle_h], [centre_x_lt - higher_crop_triangle_gap_w - higher_crop_triangle_w, height_lt - higher_crop_triangle_h], [centre_x_lt - higher_crop_triangle_gap_w , height_lt - crop_bot_h]])\n",
    "# right_triangle_pts = np.array([[width_lt, height_lt - crop_bot_h], [width_lt, height_lt - higher_crop_triangle_h], [centre_x_lt + higher_crop_triangle_gap_w + higher_crop_triangle_w, height_lt - higher_crop_triangle_h], [centre_x_lt + higher_crop_triangle_gap_w , height_lt - crop_bot_h]])\n",
    "# bottom_rectangle_pts = np.array([[0, height_lt], [0, height_lt - crop_bot_h], [width_lt, height_lt - crop_bot_h], [width_lt, height_lt]])\n",
    "\n",
    "width_lt = 640 // 4\n",
    "height_lt = 480 // 4\n",
    "mask_trapeziums = np.zeros([480 // 4, 640 // 4], dtype=\"uint8\")\n",
    "centre_x_lt = 160//2\n",
    "crop_bot_h = 62//2\n",
    "higher_crop_triangle_h = 72//2\n",
    "higher_crop_triangle_w = 75//2\n",
    "higher_crop_triangle_gap_w = 35//2\n",
    "\n",
    "left_triangle_pts = np.array([[0, height_lt - crop_bot_h], [0, height_lt - higher_crop_triangle_h], [centre_x_lt - higher_crop_triangle_gap_w - higher_crop_triangle_w, height_lt - higher_crop_triangle_h], [centre_x_lt - higher_crop_triangle_gap_w , height_lt - crop_bot_h]])\n",
    "right_triangle_pts = np.array([[width_lt, height_lt - crop_bot_h], [width_lt, height_lt - higher_crop_triangle_h], [centre_x_lt + higher_crop_triangle_gap_w + higher_crop_triangle_w, height_lt - higher_crop_triangle_h], [centre_x_lt + higher_crop_triangle_gap_w , height_lt - crop_bot_h]])\n",
    "bottom_rectangle_pts = np.array([[0, height_lt], [0, height_lt - crop_bot_h], [width_lt, height_lt - crop_bot_h], [width_lt, height_lt]])\n",
    "cv2.fillPoly(mask_trapeziums, [left_triangle_pts, right_triangle_pts, bottom_rectangle_pts], 255)\n",
    "mask_trapeziums = cv2.bitwise_not(mask_trapeziums)\n",
    "\n",
    "cv2.imshow('mask', mask_trapeziums)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
      "        33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
      "        46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
      "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
      "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "        85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
      "       111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
      "       137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,\n",
      "       150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "       163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "       176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "       202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "       215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
      "       228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
      "       241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "       267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "       280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n",
      "       293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305,\n",
      "       306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
      "       319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331,\n",
      "       332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "       345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "       371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "       384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
      "       397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
      "       410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
      "       423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "       436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "       449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "       462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
      "       475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
      "       488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
      "       501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
      "       514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
      "       527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
      "       540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
      "       553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
      "       566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
      "       579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
      "       592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
      "       605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617,\n",
      "       618, 619, 620]),)\n",
      "max width of line:  600\n",
      "max no. of pixels:  51001.0\n"
     ]
    }
   ],
   "source": [
    "# height_lt = 640\n",
    "# bot_stream_width = 480\n",
    "peak_triangle_gap = 0\n",
    "peak_triangle_width = 60\n",
    "triangle_margin = 20\n",
    "mask_gap = np.zeros([height_lt, bot_stream_width], dtype=\"uint8\")\n",
    "points = np.array([[triangle_margin, height_lt-100], [bot_stream_width-triangle_margin, height_lt-100], [int(bot_stream_width/2+peak_triangle_width), int(height_lt/2)], [int(bot_stream_width/2-peak_triangle_width),int(height_lt/2)]])\n",
    "cv2.fillConvexPoly(mask_gap, points, 255)\n",
    "# mask_gap[:height/2]\n",
    "\n",
    "mask_cols = np.amax(mask_gap, axis=0)\n",
    "mask_line_indices_x = np.where(mask_cols==255)\n",
    "print(mask_line_indices_x)\n",
    "mask_line_start_x = mask_line_indices_x[0][0] if len(mask_line_indices_x[0]) else 0\n",
    "mask_line_end_x = mask_line_indices_x[0][-1] if len(mask_line_indices_x[0]) else 0\n",
    "max_mask_width = mask_line_end_x - mask_line_start_x\n",
    "\n",
    "print(\"max width of line: \", max_mask_width)\n",
    "print(\"max no. of pixels: \", np.sum(mask_gap) / 255)\n",
    "cv2.imshow('lol', mask_gap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [0.99791232 0.99791232 0.99791232 ... 0.99791232 0.99791232 0.99791232]\n",
      " [0.99582463 0.99582463 0.99582463 ... 0.99582463 0.99582463 0.99582463]\n",
      " ...\n",
      " [0.00417537 0.00417537 0.00417537 ... 0.00417537 0.00417537 0.00417537]\n",
      " [0.00208768 0.00208768 0.00208768 ... 0.00208768 0.00208768 0.00208768]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_com = np.tile(np.linspace(-1., 1., width), (height, 1))\n",
    "y_com = np.array([[i] * width for i in np.linspace(1., 0, height)])\n",
    "print(y_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mask_gap\n",
    "# peak_triangle_gap = 0\n",
    "# peak_triangle_width = 60\n",
    "# triangle_margin = 20\n",
    "# mask_gap = np.zeros([height, width], dtype=\"uint8\")\n",
    "# points = np.array([[triangle_margin, 0], [width-triangle_margin, 0], [int(width/2+peak_triangle_width), int(height-peak_triangle_gap)], [int(width/2-peak_triangle_width), int(height-peak_triangle_gap)]])\n",
    "# cv2.fillConvexPoly(mask_gap, points, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#~ Club values\n",
    "# u_black = 110 #102 prev\n",
    "# l_blue = np.array([96, 170, 80], np.uint8)\n",
    "# u_blue = np.array([106, 245, 191], np.uint8)\n",
    "# l_green = np.array([30, 50, 60], np.uint8)\n",
    "# u_green = np.array([85, 255, 255], np.uint8)\n",
    "# l_blue = np.array([96, 170, 80], np.uint8)\n",
    "# u_blue = np.array([109, 245, 191], np.uint8)\n",
    "\n",
    "# frame_hsv = cv2.cvtColor(frame_org, cv2.COLOR_BGR2HSV)\n",
    "# frame_gray = cv2.cvtColor(frame_org, cv2.COLOR_BGR2GRAY)\n",
    "# mask_green = cv2.inRange(frame_hsv, l_green, u_green)\n",
    "# mask_blue = cv2.inRange(frame_hsv, l_blue, u_blue)\n",
    "# mask_blue[:40, :] = 0\n",
    "# mask_black_org = cv2.inRange(frame_gray, 0, u_black) - mask_green - mask_blue\n",
    "\n",
    "#~ Competition values\n",
    "l_green = np.array([60, 80, 100], np.uint8) #alternate values: 50,50,90\n",
    "u_green = np.array([80, 255, 255], np.uint8)\n",
    "l_blue = np.array([100, 135, 40], np.uint8)\n",
    "u_blue = np.array([115, 255, 255], np.uint8)\n",
    "\n",
    "l_red = np.array([0, 130, 105], np.uint8)\n",
    "u_red = np.array([10, 255, 255], np.uint8)\n",
    "l_red = np.array([170, 96, 84], np.uint8) \n",
    "u_red = np.array([180, 255, 255], np.uint8)\n",
    "crop_h_evactolt = 180\n",
    "dp = 3\n",
    "min_dist = 77 #67\n",
    "param1 = 191 #128\n",
    "param2 = 103 #62\n",
    "min_radius = 65\n",
    "max_radius = 88\n",
    "u_blackforball = 49\n",
    "u_black = 60\n",
    "u_black_lineforltfromevac = 55 #! didnt tune (from 50)\n",
    "\n",
    "frame_hsv = cv2.cvtColor(frame_org, cv2.COLOR_BGR2HSV)\n",
    "frame_gray = cv2.cvtColor(frame_org, cv2.COLOR_BGR2GRAY)\n",
    "mask_green = cv2.inRange(frame_hsv, l_green, u_green)\n",
    "mask_blue = cv2.inRange(frame_hsv, l_blue, u_blue)\n",
    "mask_blue[:40, :] = 0\n",
    "mask_black_org = cv2.inRange(frame_gray, 0, u_black)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#^ Parameters that can consider tuning? TODO: analyse the effects of changing the various params\n",
    "#^ 1. gap_check_h : essentially the region of interest for checking if there's a linegap (larger value results in faster/easier detection of linegap)\n",
    "#^ 2. powered_y : cap on value hopefully cuts down on the wiggling\n",
    "#^ 3. black_start_y and white_start_y values for endLineGap: lower black_start_y boundary means lines that are further away will also count as endlinegap;\n",
    "#^    larger white_start_y boundary means shorter line segments/segments closer can be detected??\n",
    "\n",
    "\n",
    "#^ other non essential stuff (for now):\n",
    "#^ 1. x and y com (powering and shit)\n",
    "\n",
    "\n",
    "#^ process elucidated:\n",
    "#^ if no linegap, bot uses normal mask (w horizon crop)\n",
    "#^ when bot detects linegap, switches to linegap_mask (triangle)\n",
    "#^ bot then sweeps around using the mask, & tries to catch nearest segment of line (offsetted)\n",
    "\n",
    "#^ some ideas to solve that random 90s?/wiggling\n",
    "#^ pico side: check if 5s has passed and motors have barely moved \n",
    "#^ why does it not see that nook at the 90s hsdjfhjdsh\n",
    "#^ reduce the threshold for endlinegap??? possibly by increasing white_start_y boundary???\n",
    "#^ also pico side: js reverse back to original pos\n",
    "\n",
    "#~constants\n",
    "horizon_crop_h = 40 \n",
    "gap_check_h = 155 #was 180\n",
    "\n",
    "#~black masks\n",
    "black_kernel = np.ones((7, 7), np.uint8)\n",
    "black_linegap_kernel = np.ones((11,11), np.uint8)\n",
    "mask_black = mask_black_org.copy()\n",
    "mask_black = cv2.erode(mask_black, black_kernel)\n",
    "mask_black = cv2.dilate(mask_black, black_kernel)\n",
    "\n",
    "mask_uncropped_black = mask_black.copy()\n",
    "mask_supercrop_black = mask_black.copy()\n",
    "# mask_linegap = mask_black.copy()\n",
    "\n",
    "mask_black[:horizon_crop_h, :] = 0\n",
    "mask_supercrop_black[:-gap_check_h-25, :] = 0\n",
    "mask_supercrop_black[-25:, :] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black:  479 white: 346\n",
      "black:  142 white: 95\n",
      "black_line_width: 255\n",
      "black second pixels sum: 3673.0\n",
      "second x width: 89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#~ Finding the lowest black and white pixels in UNCROPPED black\n",
    "black_row = np.amax(mask_uncropped_black, axis=1)\n",
    "black_indices_v = np.where(black_row == 255)\n",
    "black_start_y = black_indices_v[0][-1] if len(black_indices_v[0]) else 0\n",
    "black_row[black_start_y:] = 255\n",
    "white_indices = np.where(black_row == 0)\n",
    "white_start_y = white_indices[0][-1] if len(white_indices[0]) else 0\n",
    "\n",
    "black_line_height = black_start_y-white_start_y\n",
    "print(\"black: \", black_start_y, \"white:\", white_start_y) #& debug height of line\n",
    "\n",
    "\n",
    "#~ Finding next line segment\n",
    "black_row[white_start_y:] = 0\n",
    "black_indices_v2 = np.where(black_row == 255)\n",
    "black_second_start_y = black_indices_v2[0][-1] if len(black_indices_v2[0]) else 0\n",
    "black_row[black_second_start_y:] = 255\n",
    "white_indices_v2 = np.where(black_row == 0)\n",
    "white_second_start_y = white_indices_v2[0][-1] if len(white_indices_v2[0]) else 0\n",
    "print(\"black: \", black_second_start_y, \"white:\", white_second_start_y) #& debug height of second line\n",
    "\n",
    "#^ alternatively just do mask_black[white_start_y:, :] = 0 --> sets everything below white_start_y to black\n",
    "\n",
    "\n",
    "#~ Finding left and right index of black\n",
    "black_col = np.amax(mask_supercrop_black, axis=0)\n",
    "black_indices_h = np.where(black_col == 255)\n",
    "black_start_x = black_indices_h[0][0] if len(black_indices_h[0]) else 0\n",
    "black_end_x = black_indices_h[0][-1] if len(black_indices_h[0]) else 0\n",
    "\n",
    "black_line_width = black_end_x-black_start_x\n",
    "print(\"black_line_width:\", black_line_width) #& debug width of line\n",
    "\n",
    "\n",
    "#~ Next line segment \n",
    "black_second_mask = mask_black.copy()\n",
    "black_second_mask[:white_second_start_y, :] = 0\n",
    "black_second_mask[black_second_start_y:, :] = 0\n",
    "black_second_sum = np.sum(black_second_mask) /255\n",
    "cv2.imshow(\"second line\", black_second_mask)\n",
    "print(\"black second pixels sum:\", black_second_sum)\n",
    "\n",
    "if black_second_sum > 0: #^ getting (offsetted) width of second line segment \n",
    "    black_second_row = np.amax(black_second_mask[black_second_start_y-35:black_second_start_y, :], axis=0)\n",
    "    # black_second_row = np.amax(black_second_mask, axis=0) #? no difference????\n",
    "    black_second_indices = np.where(black_second_row == 255)\n",
    "    black_second_mask_start_x = black_second_indices[0][0] if len(black_second_indices[0]) else 0\n",
    "    black_second_mask_end_x = black_second_indices[0][-1] if len(black_second_indices[0]) else 0\n",
    "    black_second_mask_width = black_second_mask_end_x - black_second_mask_start_x\n",
    "\n",
    "    print(\"second x width:\", black_second_mask_width) #& debug width of line\n",
    "\n",
    "else:\n",
    "    black_second_mask_width = 0\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: Find contours of the line or something idk\n",
    "mask_xcontinuous = mask_black.copy()\n",
    "mask_xcontinuous[:white_start_y, :] = 0\n",
    "\n",
    "\n",
    "# contours, _ = cv2.findContours(mask_xcontinuous, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, _ = cv2.findContours(mask_black, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(frame_org, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "# for i in contours:\n",
    "#     if cv2.isContourConvex(i):\n",
    "#         print(True)\n",
    "        # cv2.drawContours(frame_org, i, -1, (0, 255, 0), 3)\n",
    "\n",
    "# cv2.imshow(\"black continuous line\", mask_xcontinuous)\n",
    "cv2.imshow(\"contours mask\", frame_org)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------end line gap----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#& debug area\n",
    "mask_linegap = mask_black.copy()\n",
    "# mask_continuous = mask_continuous[white_second_start_y:black_second_start_y, black_start_x:black_end_x]\n",
    "\n",
    "mask_linegap = cv2.bitwise_and(mask_gap, mask_linegap)\n",
    "\n",
    "#~ If line gap (line ending and line width small) \n",
    "if ((black_start_y < height_lt-gap_check_h or white_start_y > height_lt-gap_check_h) and black_line_width < 300): #or (black_second_start_y > 150 and white_second_start_y < 150):\n",
    "        if black_second_start_y <= 120 and not 80 <= black_second_mask_width <= 600: #or black_start_y < 200:\n",
    "            print(\">\" * 15 + 'LINE GAP' + '<' * 15)\n",
    "        mask_linegap_black = mask_black_org.copy()\n",
    "        mask_linegap_black = cv2.erode(mask_linegap_black, kernel=black_linegap_kernel)\n",
    "        mask_linegap_black = cv2.dilate(mask_linegap_black, kernel=black_linegap_kernel)\n",
    "        mask_black = cv2.bitwise_and(mask_gap, mask_linegap_black)\n",
    "        powered_y = 1\n",
    "\n",
    "else:\n",
    "    mask_black[:white_start_y, :] = 0\n",
    "\n",
    "mask_linegap_black = mask_black_org.copy()\n",
    "mask_linegap_black = cv2.erode(mask_linegap_black, kernel=black_linegap_kernel)\n",
    "mask_linegap_black = cv2.dilate(mask_linegap_black, kernel=black_linegap_kernel)\n",
    "mask_black = cv2.bitwise_and(mask_gap, mask_linegap_black)\n",
    "cv2.imshow('black', mask_black)\n",
    "\n",
    "# if black_start_y > 200 and white_start_y < 280 and black_line_width > 60: #TODO: offset mask (prev values are 400 and 250) \n",
    "#     print(\"-\" * 40 + \"end line gap\" + \"-\" * 40)\n",
    "#     end_line_gap = 1\n",
    "\n",
    "if (black_start_y > 200 and white_start_y < 165 and black_line_width > 100) or (black_second_start_y > 120 and white_second_start_y < 110 and black_second_sum > 3500 and 70 < black_second_mask_width < 600): #!!! white2ndstart = 120, 80<black_second_mask_width<600\n",
    "    # cv2.imshow(\"offset black mask\", mask_black[200:250, :])\n",
    "    print(\"-\"*40 + \"end line gap\" + \"-\" * 40)\n",
    "    \n",
    "# cv2.imshow(\"black mask\", mask_black)\n",
    "# cv2.imshow(\"black uncropped mask\", mask_uncropped_black)\n",
    "cv2.imshow(\"super cropped mask\", mask_supercrop_black)\n",
    "# cv2.imshow(\"black linegap mask\", mask_linegap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_com = np.tile(np.linspace(-1., 1., width), (height, 1))\n",
    "y_com = np.array([[i] * width for i in np.linspace(1., 0, height)])\n",
    "# print(y_com)\n",
    "\n",
    "#uncomment if necessary\n",
    "# white_start_y = 100\n",
    "# mask_black[:white_start_y, :] = 0\n",
    "# mask_black = cv2.bitwise_and(mask_gap, mask_black)\n",
    "# powered_y = 2\n",
    "powered_y = (height-40)/black_line_height if black_line_height != 0 else 1\n",
    "powered_y = powered_y ** 0.5\n",
    "print(\"y power: \", powered_y)\n",
    "powered_y = min(3.5, powered_y)\n",
    "\n",
    "\n",
    "# y_com = y_com ** powered_y\n",
    "# x_com[:, :int(width/2)] *= -1\n",
    "# x_com = x_com ** 1\n",
    "# x_com[:, :int(width/2)] *= -1\n",
    "y_black = cv2.bitwise_and(y_com, y_com, mask = mask_black)\n",
    "x_black = cv2.bitwise_and(x_com, x_com, mask = mask_black)\n",
    "\n",
    "cv2.imshow(\"yframe\", y_black)\n",
    "cv2.imshow(\"xframe\", x_black)\n",
    "\n",
    "y_resultant = np.mean(y_black) ** powered_y\n",
    "x_resultant = np.mean(x_black)\n",
    "print(y_resultant)\n",
    "print(x_resultant)\n",
    "angle = math.atan2(x_resultant, y_resultant) * 180/math.pi if y_resultant != 0 else 0\n",
    "print(angle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_com = np.tile(np.linspace(-1., 1., width), (height, 1)) #reps is (outside, inside)\n",
    "# print(x_com)\n",
    "# y_com = np.array([[i] * width for i in np.linspace(1., 1/height, height)]) #1/height is just to save pixels\n",
    "# x_com_scale = ((1-y_com) ** 0.6)\n",
    "y_com = np.array([[i] * width for i in np.linspace(1., 0, height)])\n",
    "x_com_scale = ((1-y_com) ** 0.3)\n",
    "x_com *= x_com_scale\n",
    "print(x_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#* IMAGE PROCESSING THRESHOLDS FOR LINETRACK\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m frame_org \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhsvcalibimagegreeen.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m u_black \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m110\u001b[39m \u001b[38;5;66;03m#^ DOM: prev value: 102 and 80\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ~ Real values\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#* IMAGE PROCESSING THRESHOLDS FOR LINETRACK\n",
    "frame_org = cv2.imread(\"hsvcalibimagegreeen.jpg\")\n",
    "u_black = 110 #^ DOM: prev value: 102 and 80\n",
    "\n",
    "# ~ Real values\n",
    "l_greenlt = np.array([60, 115, 100], np.uint8) #alternate values: 50,50,90\n",
    "u_greenlt = np.array([80, 255, 255], np.uint8)\n",
    "\n",
    "l_greenlt_alt = np.array([65, 55, 65], np.uint8)\n",
    "u_greenlt_alt = np.array([80, 220, 255], np.uint8)\n",
    "#~ My house's values\n",
    "# l_green = np.array([70, 90, 80], np.uint8)\n",
    "# u_green = np.array([96, 255, 255], np.uint8)\n",
    "\n",
    "#~ Real values\n",
    "l_blue = np.array([96, 170, 80], np.uint8)\n",
    "u_blue = np.array([106, 245, 191], np.uint8)\n",
    "#~ My house's values\n",
    "# l_blue = np.array([96, 170, 80], np.uint8)\n",
    "# u_blue = np.array([109, 245, 191], np.uint8)\n",
    "\n",
    "# l_blue = np.array([96, 170, 80], np.uint8)\n",
    "# u_blue = np.array([106, 245, 191], np.uint8)\n",
    "# l_green = np.array([30, 50, 60], np.uint8)\n",
    "# u_green = np.array([85, 255, 255], np.uint8)\n",
    "# l_blue = np.array([96, 170, 80], np.uint8)\n",
    "# u_blue = np.array([109, 245, 191], np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "frame_hsv = cv2.cvtColor(frame_org, cv2.COLOR_BGR2HSV)\n",
    "frame_gray = cv2.cvtColor(frame_org, cv2.COLOR_BGR2GRAY)\n",
    "mask_green = cv2.inRange(frame_hsv, l_green, u_green)\n",
    "mask_blue = cv2.inRange(frame_hsv, l_blue, u_blue)\n",
    "mask_blue[:40, :] = 0\n",
    "mask_black_org = cv2.inRange(frame_gray, 0, u_black) - mask_blue\n",
    "\n",
    "# mask_green = cv2.inRange(frame_hsv, l_greenlt, u_greenlt)\n",
    "mask_green = cv2.inRange(frame_hsv, l_green, u_green)\n",
    "\n",
    "mask_green_alt = cv2.inRange(frame_hsv, l_greenlt_alt, u_greenlt_alt)\n",
    "mask_both_green = cv2.bitwise_and(mask_green, mask_green_alt)\n",
    "mask_black_org = cv2.inRange(frame_gray, 0, u_black) - mask_both_green\n",
    "# cv2.imshow('black frame', black_mask) #& debug black mask\n",
    "\n",
    "mask_blue = cv2.inRange(frame_hsv, l_blue, u_blue) \n",
    "mask_blue[:horizon_crop_h, :] = 0\n",
    "blue_sum = np.sum(mask_blue) / 255\n",
    "\n",
    "mask_black = mask_black_org.copy()\n",
    "mask_black = cv2.erode(mask_black, black_kernel)\n",
    "mask_black = cv2.dilate(mask_black, black_kernel)\n",
    "mask_uncropped_black = mask_black.copy()\n",
    "mask_supercrop_black = mask_black.copy()\n",
    "\n",
    "mask_black[:horizon_crop_h, :] = 0\n",
    "# mask_supercrop_black[:-gap_check_h-25, :] = 0 #? shifted it up by 25 instead of 40\n",
    "# mask_supercrop_black[-25:, :] = 0 \n",
    "# end_line_gap = 0\n",
    "\n",
    "# #~ Finding the lowest black and white pixels in UNCROPPED black\n",
    "# black_row = np.amax(mask_uncropped_black, axis=1)\n",
    "# black_indices_v = np.where(black_row == 255)\n",
    "# black_start_y = black_indices_v[0][-1] if len(black_indices_v[0]) else 0\n",
    "# black_row[black_start_y:] = 255\n",
    "# white_indices = np.where(black_row == 0)\n",
    "# white_start_y = white_indices[0][-1] if len(white_indices[0]) else 0\n",
    "\n",
    "# black_line_height = black_start_y-white_start_y\n",
    "# print(\"black start: \", black_start_y, \"white: start\", white_start_y)\n",
    "\n",
    "# #~ Finding next line segment\n",
    "# black_row[white_start_y:] = 0\n",
    "# black_indices_v2 = np.where(black_row == 255)\n",
    "# black_second_start_y = black_indices_v2[0][-1] if len(black_indices_v2[0]) else 0\n",
    "# black_row[black_second_start_y:] = 255\n",
    "# white_indices_v2 = np.where(black_row == 0)\n",
    "# white_second_start_y = white_indices_v2[0][-1] if len(white_indices_v2[0]) else 0\n",
    "# print(\"2nd black: \", black_second_start_y, \"2nd white:\", white_second_start_y) #& debug height of second line\n",
    "\n",
    "# #~ Finding left and right index of black\n",
    "# black_col = np.amax(mask_supercrop_black, axis=0)\n",
    "# black_indices_h = np.where(black_col == 255)\n",
    "# black_start_x = black_indices_h[0][0] if len(black_indices_h[0]) else 0\n",
    "# black_end_x = black_indices_h[0][-1] if len(black_indices_h[0]) else 0\n",
    "# black_line_width = black_end_x-black_start_x\n",
    "\n",
    "# print(\"x width:\", black_line_width) #& debug width of line\n",
    "\n",
    "# #~ Next line segment \n",
    "# black_second_mask = mask_black.copy()\n",
    "# black_second_mask[:white_second_start_y, :] = 0\n",
    "# black_second_mask[black_second_start_y:, :] = 0\n",
    "# black_second_sum = np.sum(black_second_mask) /255\n",
    "# # cv2.imshow(\"second line\", black_second_mask)\n",
    "# print(\"black second pixels sum:\", black_second_sum)\n",
    "\n",
    "height_lt = 480\n",
    "bot_stream_width = 640\n",
    "#~ Line continuation\n",
    "# else:\n",
    "\n",
    "#~ Contours for weird close national tile\n",
    "# if white_start_y < 140:\n",
    "cv2.imshow(\"before contours\", mask_black)\n",
    "contours, _ = cv2.findContours(mask_black, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(frame_org, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow(\"with contours\", frame_org)\n",
    "\n",
    "cnts = []\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cnts.append({\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"w\": w,\n",
    "        \"h\": h\n",
    "    })\n",
    "closest_contour = max(cnts, key=lambda x: x[\"y\"]+x[\"h\"])\n",
    "# white_start_y = int(closest_contour[\"y\"] - closest_contour[\"h\"])\n",
    "contour_mask = np.zeros([height_lt, bot_stream_width], dtype=\"uint8\")\n",
    "cv2.rectangle(contour_mask,(closest_contour[\"x\"],closest_contour[\"y\"]),(closest_contour[\"x\"]+closest_contour[\"w\"],closest_contour[\"y\"]+closest_contour[\"h\"]), 255 , -1)\n",
    "# cv2.imshow(\"contours\", contour_mask)\n",
    "\n",
    "mask_black = cv2.bitwise_and(mask_black, contour_mask)\n",
    "\n",
    "    # else:\n",
    "    #     mask_black[:white_start_y, :] = 0\n",
    "cv2.imshow(\"continuous\", mask_black)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8672.0\n"
     ]
    }
   ],
   "source": [
    "l_red1evac = np.array([0, 150, 70], np.uint8)\n",
    "u_red1evac = np.array([15, 255, 255], np.uint8)\n",
    "l_red2evac = np.array([170, 150, 70], np.uint8) \n",
    "u_red2evac = np.array([180, 255, 255], np.uint8)\n",
    "\n",
    "# l_red1evac = np.array([0, 160, 70], np.uint8)\n",
    "# u_red1evac = np.array([10, 255, 255], np.uint8)\n",
    "# l_red2evac = np.array([170, 160, 70], np.uint8) \n",
    "# u_red2evac = np.array([180, 255, 255], np.uint8)\n",
    "\n",
    "frame_hsv = cv2.cvtColor(frame_org, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "mask_red1 = cv2.inRange(frame_hsv, l_red1evac, u_red1evac)\n",
    "mask_red2 = cv2.inRange(frame_hsv, l_red2evac, u_red2evac)\n",
    "mask_red = mask_red1 + mask_red2\n",
    "\n",
    "redsum = np.sum(mask_red)/255\n",
    "cv2.imshow(\"mask red\", mask_red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(redsum)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
